{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0     1     2      3      4      5\n",
      "0     1.96  0.62  0.94  69.58  98.39  55.54\n",
      "1     1.84  0.68  0.87  77.94  30.09  55.24\n",
      "2     1.53  0.71  0.81  73.18 -22.10  40.71\n",
      "3     1.21  0.71  0.72  52.25 -39.25  19.35\n",
      "4     0.98  0.69  0.62  20.39 -35.34  -0.92\n",
      "...    ...   ...   ...    ...    ...    ...\n",
      "6995 -0.31  0.96 -0.15   0.79   0.18   2.32\n",
      "6996 -0.36  0.96 -0.13   2.50  -1.04   1.04\n",
      "6997 -0.36  0.95 -0.14   2.14   0.00   0.49\n",
      "6998 -0.37  0.95 -0.15   0.43   0.67   1.77\n",
      "6999 -0.37  0.95 -0.16  -1.34  -1.34   0.67\n",
      "\n",
      "[7000 rows x 6 columns]\n",
      "         0     1     2       3       4       5\n",
      "0    -0.49  1.55 -1.63 -216.99  367.44 -317.70\n",
      "1    -0.90 -1.98 -1.87 -204.29  170.96 -265.88\n",
      "2    -1.01 -1.98 -1.87 -214.42  -27.53 -171.76\n",
      "3    -1.09 -1.98 -1.87 -206.00 -166.39  -93.57\n",
      "4    -1.00 -1.98 -1.70 -153.81 -160.71  -39.12\n",
      "...    ...   ...   ...     ...     ...     ...\n",
      "6995 -0.77  0.62  0.32    9.28    5.92    1.28\n",
      "6996 -0.84  0.62  0.31   17.33   -4.27   -3.91\n",
      "6997 -0.90  0.61  0.29   20.63  -10.25   -3.42\n",
      "6998 -0.93  0.62  0.28   17.94  -10.74    1.16\n",
      "6999 -0.91  0.63  0.29   11.47   -8.42    5.25\n",
      "\n",
      "[7000 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "punch = pd.read_csv('data/punch.csv', header = None)\n",
    "flex = pd.read_csv('data/flex.csv', header = None)\n",
    "print(punch)\n",
    "print(flex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLES_PER_GESTURE = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processData(d, v):\n",
    "    dataX = np.empty([0,SAMPLES_PER_GESTURE*6])\n",
    "    dataY = np.empty([0])\n",
    "\n",
    "    data  = d.values\n",
    "    dataNum = data.shape[0] // SAMPLES_PER_GESTURE\n",
    "\n",
    "\n",
    "    for i in tqdm(range(dataNum)):\n",
    "        tmp = []\n",
    "        for j in range(SAMPLES_PER_GESTURE):\n",
    "            tmp += [(data[i * SAMPLES_PER_GESTURE + j][0] + 4.0) / 8.0]\n",
    "            tmp += [(data[i * SAMPLES_PER_GESTURE + j][1] + 4.0) / 8.0]\n",
    "            tmp += [(data[i * SAMPLES_PER_GESTURE + j][2] + 4.0) / 8.0]\n",
    "            tmp += [(data[i * SAMPLES_PER_GESTURE + j][3] + 2000.0) / 4000.0]\n",
    "            tmp += [(data[i * SAMPLES_PER_GESTURE + j][4] + 2000.0) / 4000.0]\n",
    "            tmp += [(data[i * SAMPLES_PER_GESTURE + j][5] + 2000.0) / 4000.0]\n",
    "\n",
    "        tmp = np.array(tmp)\n",
    "\n",
    "        tmp = np.expand_dims(tmp, axis = 0)\n",
    "\n",
    "        dataX = np.concatenate((dataX, tmp), axis = 0)\n",
    "        dataY = np.append(dataY, v)\n",
    "\n",
    "    return dataX, dataY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 1446.83it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 1448.20it/s]\n"
     ]
    }
   ],
   "source": [
    "punchX, punchY = processData(punch, 0)\n",
    "flexX, flexY = processData(flex, 1)\n",
    "dataX = np.concatenate((punchX, flexX), axis = 0)\n",
    "dataY = np.concatenate((punchY, flexY), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[154  55  96 174 167 131  27  25 175   7 182   6 125 100  78 160 189  35\n",
      " 196  49   4 165  97  72 148  68  37  19  34  69  53  56 185 129  51  50\n",
      " 172  61 106  43 179 147 134 135 176  38  57 121   3 149 136  12  60  54\n",
      " 183  86  85  33 158 195  64 142  47  62   5  13 193 105 145  79 156 132\n",
      "  44 128  32 168  73  95  93 117 150  21 120  41  46  99 180 177  74 198\n",
      " 110 157  82  45  14  90 123 112   0  29  77  91 194 102 114 119 191  84\n",
      " 143  87 188 115  66 109 137  83  10  31 184  89  24 163 104  92 171  48\n",
      " 118  80  18  11 130  30   1  58 166 192  70   8  23 190  15  81 111  52\n",
      " 151 178 107  75  36  88 133 169 101 197   2  65   9 140  71  40 103 170\n",
      " 173 159  28  98 126 139  26  20 164  42 186 144 153 138  39 127 122 141\n",
      "  59  17 187 152 113 161  22  63  67 116 199 181  94  16 162 155  76 146\n",
      " 108 124]\n"
     ]
    }
   ],
   "source": [
    "permutationTrain = np.random.permutation(dataX.shape[0])\n",
    "print(permutationTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1.\n",
      " 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1.\n",
      " 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0.\n",
      " 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0.\n",
      " 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1.\n",
      " 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "dataX = dataX[permutationTrain]\n",
    "dataY = dataY[permutationTrain]\n",
    "print(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vfoldSize = int(dataX.shape[0]/100*20)\n",
    "\n",
    "xTest = dataX[0:vfoldSize]\n",
    "yTest = dataY[0:vfoldSize]\n",
    "\n",
    "xTrain = dataX[vfoldSize:dataX.shape[0]]\n",
    "yTrain = dataY[vfoldSize:dataY.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(32, input_shape =(6*SAMPLES_PER_GESTURE,), activation='relu'))\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(2, activation='softmax'))\n",
    "adam = keras.optimizers.Adam()\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                13472     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 14,034\n",
      "Trainable params: 14,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/200\n",
      "160/160 [==============================] - 1s 9ms/sample - loss: 0.7056 - sparse_categorical_accuracy: 0.5250 - val_loss: 0.7012 - val_sparse_categorical_accuracy: 0.4250\n",
      "Epoch 2/200\n",
      "160/160 [==============================] - 1s 3ms/sample - loss: 0.6945 - sparse_categorical_accuracy: 0.5063 - val_loss: 0.6591 - val_sparse_categorical_accuracy: 0.7000\n",
      "Epoch 3/200\n",
      "160/160 [==============================] - 1s 3ms/sample - loss: 0.6408 - sparse_categorical_accuracy: 0.6313 - val_loss: 0.5928 - val_sparse_categorical_accuracy: 0.7500\n",
      "Epoch 4/200\n",
      "160/160 [==============================] - 1s 3ms/sample - loss: 0.6005 - sparse_categorical_accuracy: 0.6187 - val_loss: 0.5986 - val_sparse_categorical_accuracy: 0.5750\n",
      "Epoch 5/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.5449 - sparse_categorical_accuracy: 0.7375 - val_loss: 0.6080 - val_sparse_categorical_accuracy: 0.6500\n",
      "Epoch 6/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.4607 - sparse_categorical_accuracy: 0.7937 - val_loss: 0.5979 - val_sparse_categorical_accuracy: 0.6750\n",
      "Epoch 7/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.4081 - sparse_categorical_accuracy: 0.8313 - val_loss: 0.3031 - val_sparse_categorical_accuracy: 0.9250\n",
      "Epoch 8/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.3274 - sparse_categorical_accuracy: 0.8562 - val_loss: 0.2635 - val_sparse_categorical_accuracy: 0.9500\n",
      "Epoch 9/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.2980 - sparse_categorical_accuracy: 0.8938 - val_loss: 0.6083 - val_sparse_categorical_accuracy: 0.7000\n",
      "Epoch 10/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.2193 - sparse_categorical_accuracy: 0.9375 - val_loss: 0.3287 - val_sparse_categorical_accuracy: 0.7500\n",
      "Epoch 11/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.2225 - sparse_categorical_accuracy: 0.9000 - val_loss: 0.1409 - val_sparse_categorical_accuracy: 0.9750\n",
      "Epoch 12/200\n",
      "160/160 [==============================] - 1s 3ms/sample - loss: 0.1713 - sparse_categorical_accuracy: 0.9500 - val_loss: 0.1267 - val_sparse_categorical_accuracy: 0.9750\n",
      "Epoch 13/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.1946 - sparse_categorical_accuracy: 0.9187 - val_loss: 0.3864 - val_sparse_categorical_accuracy: 0.7750\n",
      "Epoch 14/200\n",
      "160/160 [==============================] - 1s 3ms/sample - loss: 0.1171 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.2738 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 15/200\n",
      "160/160 [==============================] - 1s 3ms/sample - loss: 0.1531 - sparse_categorical_accuracy: 0.9250 - val_loss: 0.1561 - val_sparse_categorical_accuracy: 0.9250\n",
      "Epoch 16/200\n",
      "160/160 [==============================] - 0s 3ms/sample - loss: 0.1638 - sparse_categorical_accuracy: 0.9375 - val_loss: 0.1593 - val_sparse_categorical_accuracy: 0.9750\n",
      "Epoch 17/200\n",
      "160/160 [==============================] - 0s 3ms/sample - loss: 0.1626 - sparse_categorical_accuracy: 0.9375 - val_loss: 0.1288 - val_sparse_categorical_accuracy: 0.9500\n",
      "Epoch 18/200\n",
      "160/160 [==============================] - 0s 3ms/sample - loss: 0.1056 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.0845 - val_sparse_categorical_accuracy: 0.9750\n",
      "Epoch 19/200\n",
      "160/160 [==============================] - 1s 3ms/sample - loss: 0.1363 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.1149 - val_sparse_categorical_accuracy: 0.9750\n",
      "Epoch 20/200\n",
      "160/160 [==============================] - 1s 3ms/sample - loss: 0.2352 - sparse_categorical_accuracy: 0.9375 - val_loss: 0.2045 - val_sparse_categorical_accuracy: 0.8750\n",
      "Epoch 21/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.1273 - sparse_categorical_accuracy: 0.9438 - val_loss: 0.7172 - val_sparse_categorical_accuracy: 0.7500\n",
      "Epoch 22/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.1021 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.1327 - val_sparse_categorical_accuracy: 0.9750\n",
      "Epoch 23/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.1255 - sparse_categorical_accuracy: 0.9500 - val_loss: 1.0536 - val_sparse_categorical_accuracy: 0.6750\n",
      "Epoch 24/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.1216 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.0828 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 25/200\n",
      "160/160 [==============================] - 1s 3ms/sample - loss: 0.1251 - sparse_categorical_accuracy: 0.9563 - val_loss: 0.0719 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 26/200\n",
      "160/160 [==============================] - 1s 3ms/sample - loss: 0.1111 - sparse_categorical_accuracy: 0.9438 - val_loss: 0.1016 - val_sparse_categorical_accuracy: 0.9500\n",
      "Epoch 27/200\n",
      "160/160 [==============================] - 1s 3ms/sample - loss: 0.1062 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.1485 - val_sparse_categorical_accuracy: 0.9500\n",
      "Epoch 28/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.1645 - sparse_categorical_accuracy: 0.9438 - val_loss: 0.0640 - val_sparse_categorical_accuracy: 0.9750\n",
      "Epoch 29/200\n",
      "160/160 [==============================] - 0s 3ms/sample - loss: 0.1205 - sparse_categorical_accuracy: 0.9563 - val_loss: 0.1005 - val_sparse_categorical_accuracy: 0.9500\n",
      "Epoch 30/200\n",
      "160/160 [==============================] - 1s 3ms/sample - loss: 0.0555 - sparse_categorical_accuracy: 0.9875 - val_loss: 0.0602 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 31/200\n",
      "160/160 [==============================] - 0s 3ms/sample - loss: 0.1257 - sparse_categorical_accuracy: 0.9438 - val_loss: 0.0858 - val_sparse_categorical_accuracy: 0.9750\n",
      "Epoch 32/200\n",
      "160/160 [==============================] - 0s 3ms/sample - loss: 0.0867 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.0516 - val_sparse_categorical_accuracy: 0.9750\n",
      "Epoch 33/200\n",
      "160/160 [==============================] - 0s 3ms/sample - loss: 0.0768 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.0528 - val_sparse_categorical_accuracy: 0.9750\n",
      "Epoch 34/200\n",
      "160/160 [==============================] - 1s 3ms/sample - loss: 0.0710 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.0517 - val_sparse_categorical_accuracy: 0.9750\n",
      "Epoch 35/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.1412 - sparse_categorical_accuracy: 0.9375 - val_loss: 0.1330 - val_sparse_categorical_accuracy: 0.9750\n",
      "Epoch 36/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.1648 - sparse_categorical_accuracy: 0.9250 - val_loss: 0.7969 - val_sparse_categorical_accuracy: 0.7750\n",
      "Epoch 37/200\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.0916 - sparse_categorical_accuracy: 0.972 - 1s 4ms/sample - loss: 0.0917 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.0561 - val_sparse_categorical_accuracy: 0.9750\n",
      "Epoch 38/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.1109 - sparse_categorical_accuracy: 0.9563 - val_loss: 0.0864 - val_sparse_categorical_accuracy: 0.9750\n",
      "Epoch 39/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.1077 - sparse_categorical_accuracy: 0.9500 - val_loss: 0.0572 - val_sparse_categorical_accuracy: 0.9750\n",
      "Epoch 40/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.1087 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.0826 - val_sparse_categorical_accuracy: 0.9750\n",
      "Epoch 41/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.0790 - sparse_categorical_accuracy: 0.9812 - val_loss: 0.0809 - val_sparse_categorical_accuracy: 0.9750\n",
      "Epoch 42/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.0817 - sparse_categorical_accuracy: 0.9812 - val_loss: 0.2091 - val_sparse_categorical_accuracy: 0.8500\n",
      "Epoch 43/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.1331 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.0679 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 44/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.0847 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.0606 - val_sparse_categorical_accuracy: 0.9750\n",
      "Epoch 45/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.1126 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.1041 - val_sparse_categorical_accuracy: 0.9500\n",
      "Epoch 46/200\n",
      "160/160 [==============================] - 1s 3ms/sample - loss: 0.0970 - sparse_categorical_accuracy: 0.9500 - val_loss: 0.1179 - val_sparse_categorical_accuracy: 0.9750\n",
      "Epoch 47/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.0831 - sparse_categorical_accuracy: 0.9812 - val_loss: 0.0659 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 48/200\n",
      "160/160 [==============================] - 0s 3ms/sample - loss: 0.0561 - sparse_categorical_accuracy: 0.9812 - val_loss: 0.0703 - val_sparse_categorical_accuracy: 0.9750\n",
      "Epoch 49/200\n",
      "160/160 [==============================] - 0s 3ms/sample - loss: 0.1427 - sparse_categorical_accuracy: 0.9688 - val_loss: 1.3124 - val_sparse_categorical_accuracy: 0.7000\n",
      "Epoch 50/200\n",
      "160/160 [==============================] - 0s 3ms/sample - loss: 0.0852 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.0501 - val_sparse_categorical_accuracy: 0.9750\n",
      "Epoch 51/200\n",
      "160/160 [==============================] - 0s 3ms/sample - loss: 0.1505 - sparse_categorical_accuracy: 0.9438 - val_loss: 0.0972 - val_sparse_categorical_accuracy: 0.9500\n",
      "Epoch 52/200\n",
      "160/160 [==============================] - 0s 3ms/sample - loss: 0.0861 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.0503 - val_sparse_categorical_accuracy: 0.9750\n",
      "Epoch 53/200\n",
      "160/160 [==============================] - 0s 3ms/sample - loss: 0.0797 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.3667 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 54/200\n",
      "160/160 [==============================] - 1s 3ms/sample - loss: 0.0861 - sparse_categorical_accuracy: 0.9563 - val_loss: 0.0897 - val_sparse_categorical_accuracy: 0.9750\n",
      "Epoch 55/200\n",
      "160/160 [==============================] - 1s 3ms/sample - loss: 0.1228 - sparse_categorical_accuracy: 0.9500 - val_loss: 0.0739 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 56/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.0921 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.0832 - val_sparse_categorical_accuracy: 0.9750\n",
      "Epoch 57/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.0970 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.0611 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 58/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.0912 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.0498 - val_sparse_categorical_accuracy: 0.9750\n",
      "Epoch 59/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.0788 - sparse_categorical_accuracy: 0.9812 - val_loss: 0.0717 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 60/200\n",
      "160/160 [==============================] - 1s 3ms/sample - loss: 0.1398 - sparse_categorical_accuracy: 0.9500 - val_loss: 0.2711 - val_sparse_categorical_accuracy: 0.8750\n",
      "Epoch 61/200\n",
      "160/160 [==============================] - 1s 3ms/sample - loss: 0.0877 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.3413 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 62/200\n",
      "160/160 [==============================] - 0s 3ms/sample - loss: 0.0761 - sparse_categorical_accuracy: 0.9812 - val_loss: 0.0755 - val_sparse_categorical_accuracy: 0.9750\n",
      "Epoch 63/200\n",
      "160/160 [==============================] - 0s 3ms/sample - loss: 0.1033 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.0808 - val_sparse_categorical_accuracy: 0.9750\n",
      "Epoch 64/200\n",
      "160/160 [==============================] - 0s 3ms/sample - loss: 0.0983 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.0589 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "160/160 [==============================] - 0s 3ms/sample - loss: 0.1147 - sparse_categorical_accuracy: 0.9563 - val_loss: 0.1052 - val_sparse_categorical_accuracy: 0.9500\n",
      "Epoch 66/200\n",
      "160/160 [==============================] - 0s 3ms/sample - loss: 0.0862 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.0506 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "160/160 [==============================] - 0s 3ms/sample - loss: 0.0835 - sparse_categorical_accuracy: 0.9563 - val_loss: 0.0514 - val_sparse_categorical_accuracy: 0.9750\n",
      "Epoch 68/200\n",
      "160/160 [==============================] - 0s 3ms/sample - loss: 0.1087 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.0475 - val_sparse_categorical_accuracy: 0.9750\n",
      "Epoch 69/200\n",
      "160/160 [==============================] - 0s 3ms/sample - loss: 0.1032 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.0872 - val_sparse_categorical_accuracy: 0.9750\n",
      "Epoch 70/200\n",
      "160/160 [==============================] - 0s 3ms/sample - loss: 0.0567 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.6670 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 71/200\n",
      "160/160 [==============================] - 0s 3ms/sample - loss: 0.1119 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.0990 - val_sparse_categorical_accuracy: 0.9500\n",
      "Epoch 72/200\n",
      "160/160 [==============================] - 0s 3ms/sample - loss: 0.0880 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.0666 - val_sparse_categorical_accuracy: 0.9750\n",
      "Epoch 73/200\n",
      "160/160 [==============================] - 1s 3ms/sample - loss: 0.1224 - sparse_categorical_accuracy: 0.9500 - val_loss: 0.1123 - val_sparse_categorical_accuracy: 0.9500\n",
      "Epoch 74/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.0850 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.0633 - val_sparse_categorical_accuracy: 0.9750\n",
      "Epoch 75/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.0922 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.0517 - val_sparse_categorical_accuracy: 0.9750\n",
      "Epoch 76/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.1294 - sparse_categorical_accuracy: 0.9438 - val_loss: 0.0624 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.0857 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.0577 - val_sparse_categorical_accuracy: 0.9750\n",
      "Epoch 78/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.1079 - sparse_categorical_accuracy: 0.9500 - val_loss: 0.0480 - val_sparse_categorical_accuracy: 0.9750\n",
      "Epoch 79/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.0926 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.3531 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 80/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.0729 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.0450 - val_sparse_categorical_accuracy: 0.9750\n",
      "Epoch 81/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.0846 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.0458 - val_sparse_categorical_accuracy: 0.9750\n",
      "Epoch 82/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.0933 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.1484 - val_sparse_categorical_accuracy: 0.9500\n",
      "Epoch 83/200\n",
      "160/160 [==============================] - 1s 3ms/sample - loss: 0.0882 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.4604 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 84/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.0823 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.5864 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 85/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.1107 - sparse_categorical_accuracy: 0.9312 - val_loss: 0.3939 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 86/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.0887 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.1205 - val_sparse_categorical_accuracy: 0.9500\n",
      "Epoch 87/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.0864 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.6166 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 88/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.0769 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.8391 - val_sparse_categorical_accuracy: 0.7750\n",
      "Epoch 89/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.0720 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.4885 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 90/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.1119 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.0427 - val_sparse_categorical_accuracy: 0.9750\n",
      "Epoch 91/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.1195 - sparse_categorical_accuracy: 0.9500 - val_loss: 0.1538 - val_sparse_categorical_accuracy: 0.9500\n",
      "Epoch 92/200\n",
      "160/160 [==============================] - 1s 4ms/sample - loss: 0.0404 - sparse_categorical_accuracy: 0.9937 - val_loss: 0.0910 - val_sparse_categorical_accuracy: 0.9500\n",
      "Epoch 93/200\n",
      "160/160 [==============================] - 1s 3ms/sample - loss: 0.0719 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.0465 - val_sparse_categorical_accuracy: 0.9750\n",
      "Epoch 94/200\n",
      "160/160 [==============================] - 1s 3ms/sample - loss: 0.1501 - sparse_categorical_accuracy: 0.9375 - val_loss: 0.0386 - val_sparse_categorical_accuracy: 0.9750\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(xTrain, yTrain, batch_size=1, validation_data=(xTest, yTest), epochs=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
